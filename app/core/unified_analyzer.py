"""
ç»Ÿä¸€åˆ†æå™¨
å°†æ•´ä¸ªå¯¹è¯æ–‡ä»¶ä½œä¸ºæ•´ä½“è¿›è¡Œåˆ†æï¼Œè€Œä¸æ˜¯åˆ†è½®æ¬¡å¤„ç†
"""

import time
from typing import List, Dict, Any, Optional, Callable
from .tag_extractor import TagExtractor
from .tag_manager import TagManager
from .models import UserProfile
from .conversation_summarizer import ConversationSummarizer
from .summary_manager import SummaryManager


class UnifiedAnalyzer:
    """ç»Ÿä¸€åˆ†æå™¨ - æ•´ä½“åˆ†æå¯¹è¯å†…å®¹"""
    
    def __init__(self, tag_extractor: TagExtractor, tag_manager: TagManager, user_id: str):
        self.tag_extractor = tag_extractor
        self.tag_manager = tag_manager
        self.user_id = user_id
        self.conversation_summarizer = ConversationSummarizer(user_id)
    
    def analyze_all_conversations(
        self, 
        user_id: str,
        conversations: List[Dict[str, Any]], 
        progress_callback: Optional[Callable[[int, int, str], None]] = None,
        generate_summaries: bool = True
    ) -> Dict[str, Any]:
        """
        æ•´ä½“åˆ†ææ‰€æœ‰å¯¹è¯å†…å®¹
        
        Args:
            user_id: ç”¨æˆ·ID
            conversations: å¯¹è¯åˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            generate_summaries: æ˜¯å¦ç”Ÿæˆæ‘˜è¦
            
        Returns:
            åˆ†æç»“æœ
        """
        total_conversations = len(conversations)
        
        print(f"ğŸš€ å¼€å§‹æ•´ä½“åˆ†æ {total_conversations} è½®å¯¹è¯...")
        
        if progress_callback:
            progress_callback(1, 3, "æ­£åœ¨æ•´ä½“åˆ†æå¯¹è¯å†…å®¹...")
        
        # 1. æ„å»ºå®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡
        full_context = self._build_full_context(conversations)
        print(f"ğŸ“ æ„å»ºå®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæ€»é•¿åº¦: {len(full_context)} å­—ç¬¦")
        
        # 2. æ•´ä½“æå–æ ‡ç­¾
        extracted_tags = {}
        try:
            print("ğŸ” å¼€å§‹æ•´ä½“æ ‡ç­¾æå–...")
            extracted_tags = self.tag_extractor.extract_tags_from_text(full_context)
            print(f"âœ… æ•´ä½“æ ‡ç­¾æå–æˆåŠŸ: {type(extracted_tags)}")
            
            # è®¡ç®—æ ‡ç­¾æ€»æ•°
            total_extracted_tags = sum(len(tags) for tags in extracted_tags.values())
            print(f"ğŸ“‹ å…±æå–åˆ° {total_extracted_tags} ä¸ªæ ‡ç­¾")
            
        except Exception as extract_error:
            print(f"âŒ æ•´ä½“æ ‡ç­¾æå–å¤±è´¥: {str(extract_error)}")
            import traceback
            traceback.print_exc()
        
        if progress_callback:
            progress_callback(2, 3, "æ­£åœ¨ç”Ÿæˆå¯¹è¯æ‘˜è¦...")
        
        # 3. ç”Ÿæˆæ•´ä½“æ‘˜è¦æˆ–åˆ†æ®µæ‘˜è¦
        conversation_summaries = []
        summary_statistics = {}
        
        if generate_summaries:
            try:
                print("ğŸ“ å¼€å§‹ç”Ÿæˆå¯¹è¯æ‘˜è¦...")
                
                # å¯ä»¥é€‰æ‹©æ•´ä½“æ‘˜è¦æˆ–åˆ†æ®µæ‘˜è¦
                if len(conversations) <= 10:  # å¯¹è¯æ•°é‡è¾ƒå°‘æ—¶ï¼Œå¯ä»¥ç”Ÿæˆè¯¦ç»†çš„åˆ†æ®µæ‘˜è¦
                    conversation_summaries = self._generate_detailed_summaries(conversations)
                else:  # å¯¹è¯æ•°é‡è¾ƒå¤šæ—¶ï¼Œç”Ÿæˆæ•´ä½“æ‘˜è¦
                    conversation_summaries = self._generate_unified_summary(conversations)
                
                summary_statistics = self._calculate_summary_statistics(conversation_summaries)
                print(f"âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆï¼ŒæˆåŠŸç‡: {summary_statistics.get('success_rate', 0)}%")
                
            except Exception as summary_error:
                print(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(summary_error)}")
                import traceback
                traceback.print_exc()
        
        if progress_callback:
            progress_callback(3, 3, "æ­£åœ¨æ›´æ–°ç”¨æˆ·ç”»åƒ...")
        
        # 4. æ›´æ–°ç”¨æˆ·ç”»åƒ
        updated_profile = None
        total_updated_tags = 0
        
        if extracted_tags:
            try:
                print("ğŸ”„ å¼€å§‹æ›´æ–°ç”¨æˆ·ç”»åƒ...")
                updated_profile = self.tag_manager.update_tags(extracted_tags)
                total_updated_tags = sum(len(tags) for tags in extracted_tags.values())
                print(f"âœ… ç”¨æˆ·ç”»åƒæ›´æ–°å®Œæˆï¼Œæ›´æ–°æ ‡ç­¾æ•°: {total_updated_tags}")
                
            except Exception as update_error:
                print(f"âŒ ç”¨æˆ·ç”»åƒæ›´æ–°å¤±è´¥: {str(update_error)}")
                import traceback
                traceback.print_exc()
        
        # 5. ä¿å­˜æ‘˜è¦æ•°æ®
        if conversation_summaries:
            try:
                summary_manager = SummaryManager()
                summary_manager.save_batch_summaries(user_id, conversation_summaries)
                print(f"âœ… æˆåŠŸä¿å­˜ {len(conversation_summaries)} ä¸ªä¼šè¯æ‘˜è¦")
            except Exception as save_error:
                print(f"âŒ ä¿å­˜æ‘˜è¦å¤±è´¥: {str(save_error)}")
        
        # 6. æ„å»ºåˆ†æç»“æœ
        analysis_result = {
            'total_conversations': total_conversations,
            'processed_conversations': total_conversations,
            'total_extracted_tags': sum(len(tags) for tags in extracted_tags.values()) if extracted_tags else 0,
            'total_updated_tags': total_updated_tags,
            'user_profile': updated_profile.to_dict() if updated_profile else None,
            'conversation_summaries': conversation_summaries,
            'summary_statistics': summary_statistics,
            'extracted_tags_by_category': {
                category: [tag.to_dict() for tag in tags] 
                for category, tags in extracted_tags.items()
            } if extracted_tags else {},
            'analysis_method': 'unified',  # æ ‡è¯†ä¸ºæ•´ä½“åˆ†æ
            'summary': self._generate_analysis_summary(
                total_conversations, 
                sum(len(tags) for tags in extracted_tags.values()) if extracted_tags else 0,
                conversation_summaries
            )
        }
        
        print(f"âœ… æ•´ä½“åˆ†æå®Œæˆ!")
        print(f"   ğŸ“Š æ€»å¯¹è¯æ•°: {total_conversations}")
        print(f"   âœ… æˆåŠŸå¤„ç†: {total_conversations}")
        print(f"   ğŸ·ï¸ æå–æ ‡ç­¾: {analysis_result['total_extracted_tags']}")
        print(f"   ğŸ”„ æ›´æ–°æ ‡ç­¾: {total_updated_tags}")
        if updated_profile and hasattr(updated_profile, 'profile_maturity'):
            print(f"   ğŸ“ˆ ç”»åƒæˆç†Ÿåº¦: {updated_profile.profile_maturity:.2%}")
        
        return analysis_result
    
    def _build_full_context(self, conversations: List[Dict[str, Any]]) -> str:
        """æ„å»ºå®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
        context_parts = []
        
        for i, conversation in enumerate(conversations, 1):
            user_message = conversation.get('user', '')
            assistant_message = conversation.get('assistant', '')
            
            if user_message:
                context_parts.append(f"=== å¯¹è¯ {i} ===")
                context_parts.append(f"ç”¨æˆ·ï¼š{user_message}")
                if assistant_message:
                    context_parts.append(f"åŠ©æ‰‹ï¼š{assistant_message}")
                context_parts.append("")  # ç©ºè¡Œåˆ†éš”
        
        return "\n".join(context_parts)
    
    def _generate_detailed_summaries(self, conversations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆè¯¦ç»†çš„åˆ†æ®µæ‘˜è¦ï¼ˆé€‚ç”¨äºå°‘é‡å¯¹è¯ï¼‰"""
        summaries = []
        
        for i, conversation in enumerate(conversations):
            try:
                user_message = conversation.get('user', '')
                assistant_message = conversation.get('assistant', '')
                
                if not user_message:
                    summaries.append({
                        'conversation_index': i + 1,
                        'success': False,
                        'error': 'ç”¨æˆ·æ¶ˆæ¯ä¸ºç©º'
                    })
                    continue
                
                print(f"ğŸ“ ç”Ÿæˆç¬¬ {i + 1} è½®å¯¹è¯æ‘˜è¦...")
                summary_result = self.conversation_summarizer.generate_summary(user_message, assistant_message)
                summary_result['conversation_index'] = i + 1
                summaries.append(summary_result)
                
                # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…APIè¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(0.1)
                
            except Exception as e:
                print(f"âŒ ç¬¬ {i + 1} è½®å¯¹è¯æ‘˜è¦ç”Ÿæˆå¼‚å¸¸: {e}")
                summaries.append({
                    'conversation_index': i + 1,
                    'success': False,
                    'error': str(e)
                })
        
        return summaries
    
    def _generate_unified_summary(self, conversations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç»Ÿä¸€æ‘˜è¦ï¼ˆé€‚ç”¨äºå¤§é‡å¯¹è¯ï¼‰"""
        print("ğŸ“ ç”Ÿæˆæ•´ä½“å¯¹è¯æ‘˜è¦...")
        
        # å°†æ‰€æœ‰å¯¹è¯åˆå¹¶ä¸ºä¸€ä¸ªæ•´ä½“è¿›è¡Œæ‘˜è¦
        all_user_messages = []
        all_assistant_messages = []
        
        for conversation in conversations:
            user_msg = conversation.get('user', '').strip()
            assistant_msg = conversation.get('assistant', '').strip()
            if user_msg:
                all_user_messages.append(user_msg)
            if assistant_msg:
                all_assistant_messages.append(assistant_msg)
        
        # æ„å»ºæ•´ä½“å¯¹è¯å†…å®¹
        combined_user_content = " ".join(all_user_messages)
        combined_assistant_content = " ".join(all_assistant_messages)
        
        try:
            # ç”Ÿæˆæ•´ä½“æ‘˜è¦
            summary_result = self.conversation_summarizer.generate_summary(
                combined_user_content, 
                combined_assistant_content
            )
            
            # å°†æ•´ä½“æ‘˜è¦åº”ç”¨åˆ°æ‰€æœ‰å¯¹è¯
            summaries = []
            for i in range(len(conversations)):
                summary_copy = summary_result.copy()
                summary_copy['conversation_index'] = i + 1
                summary_copy['is_unified_summary'] = True  # æ ‡è®°ä¸ºæ•´ä½“æ‘˜è¦
                summaries.append(summary_copy)
            
            print(f"âœ… æ•´ä½“æ‘˜è¦ç”ŸæˆæˆåŠŸï¼Œåº”ç”¨åˆ° {len(conversations)} è½®å¯¹è¯")
            return summaries
            
        except Exception as e:
            print(f"âŒ æ•´ä½“æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›å¤±è´¥ç»“æœ
            return [{
                'conversation_index': i + 1,
                'success': False,
                'error': f"æ•´ä½“æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}",
                'is_unified_summary': True
            } for i in range(len(conversations))]
    
    def _calculate_summary_statistics(self, summaries: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯"""
        if not summaries:
            return {}
        
        successful_summaries = [s for s in summaries if s.get('success', False)]
        success_rate = (len(successful_summaries) / len(summaries)) * 100
        
        # ç»Ÿè®¡åŒ»ç–—ç³»ç»Ÿå’Œé£é™©ç­‰çº§
        medical_systems = {}
        risk_levels = {}
        
        for summary in successful_summaries:
            if summary.get('summary'):
                medical_system = summary['summary'].get('æ¶‰åŠç³»ç»Ÿ', '')
                if medical_system and medical_system != 'N/A':
                    medical_systems[medical_system] = medical_systems.get(medical_system, 0) + 1
                
                risk_level = summary['summary'].get('é£é™©è¯„ä¼°', '')
                if risk_level and risk_level != 'N/A':
                    risk_levels[risk_level] = risk_levels.get(risk_level, 0) + 1
        
        return {
            'total_summaries': len(summaries),
            'successful_summaries': len(successful_summaries),
            'success_rate': round(success_rate, 1),
            'medical_systems': medical_systems,
            'risk_levels': risk_levels
        }
    
    def _generate_analysis_summary(self, total_conversations: int, total_tags: int, summaries: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææ€»ç»“"""
        success_rate = 100.0  # æ•´ä½“åˆ†æçš„æˆåŠŸç‡é€šå¸¸æ˜¯100%
        average_tags = total_tags / total_conversations if total_conversations > 0 else 0
        
        # ç»Ÿè®¡æ ‡ç­¾åˆ†ç±»ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        tag_categories = {}
        
        return {
            'total_conversations': total_conversations,
            'success_rate': success_rate,
            'average_tags_per_conversation': round(average_tags, 1),
            'tag_categories': tag_categories,
            'analysis_method': 'unified'
        }
